{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-required-libraries-and-set-configurations\" data-toc-modified-id=\"Import-required-libraries-and-set-configurations-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import required libraries and set configurations</a></span></li><li><span><a href=\"#Batch-read-csv-files-and-append-them\" data-toc-modified-id=\"Batch-read-csv-files-and-append-them-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Batch read csv files and append them</a></span></li><li><span><a href=\"#Treat-missing-values\" data-toc-modified-id=\"Treat-missing-values-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Treat missing values</a></span></li><li><span><a href=\"#Map-values-according-to-data-dictionary\" data-toc-modified-id=\"Map-values-according-to-data-dictionary-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Map values according to data dictionary</a></span></li><li><span><a href=\"#Modify-date-column-appropriately\" data-toc-modified-id=\"Modify-date-column-appropriately-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modify date column appropriately</a></span></li><li><span><a href=\"#Making-lag-variables\" data-toc-modified-id=\"Making-lag-variables-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Making lag variables</a></span></li><li><span><a href=\"#Remove-columns-which-are-not-required\" data-toc-modified-id=\"Remove-columns-which-are-not-required-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Remove columns which are not required</a></span></li><li><span><a href=\"#Making-the-key-to-aggregate-data-at\" data-toc-modified-id=\"Making-the-key-to-aggregate-data-at-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Making the key to aggregate data at</a></span></li><li><span><a href=\"#Dummify-categorical-variables\" data-toc-modified-id=\"Dummify-categorical-variables-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Dummify categorical variables</a></span></li><li><span><a href=\"#Aggregate-the-data\" data-toc-modified-id=\"Aggregate-the-data-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Aggregate the data</a></span></li><li><span><a href=\"#Capping-the-target-variable\" data-toc-modified-id=\"Capping-the-target-variable-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Capping the target variable</a></span></li><li><span><a href=\"#Modify-the-dummy-variables-appropriately\" data-toc-modified-id=\"Modify-the-dummy-variables-appropriately-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Modify the dummy variables appropriately</a></span></li><li><span><a href=\"#Output-master-data-into-pickle-for-modelling-purpose\" data-toc-modified-id=\"Output-master-data-into-pickle-for-modelling-purpose-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Output master data into pickle for modelling purpose</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries and set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration variables\n",
    "DATA_INPUT = '../data/raw'\n",
    "DATA_OUTPUT = '../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch read csv files and append them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RO RANDOM W9-1.csv is being read...\n",
      "RO RANDOM W9-1.csv has been appended...\n",
      "RO RANDOM W9-2.csv is being read...\n",
      "RO RANDOM W9-2.csv has been appended...\n",
      "RO RANDOM W10-1.csv is being read...\n",
      "RO RANDOM W10-1.csv has been appended...\n",
      "RO RANDOM W10-2.csv is being read...\n",
      "RO RANDOM W10-2.csv has been appended...\n",
      "RO RANDOM W8-2.csv is being read...\n",
      "RO RANDOM W8-2.csv has been appended...\n",
      "RO RANDOM W8-1.csv is being read...\n",
      "RO RANDOM W8-1.csv has been appended...\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to append the csvs to\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the list of files in the path\n",
    "for file in os.listdir(DATA_INPUT):\n",
    "    \n",
    "    # Consider only csv files\n",
    "    if 'csv' in file:   \n",
    "        \n",
    "        # Find the path of the csv file\n",
    "        pathname = os.path.join(DATA_INPUT,file)\n",
    "        \n",
    "        # Read the csv file\n",
    "        print(\"%s is being read...\" % (file))\n",
    "        temp = pd.read_csv(pathname, low_memory=False, encoding='latin1')\n",
    "        \n",
    "        # Strip space from headers so as to not encounter any appending issues\n",
    "        temp.columns = temp.columns.str.replace(' ','')\n",
    "        \n",
    "        # Append the file towards the end sequentially\n",
    "        df = df.append(temp)\n",
    "        print(\"%s has been appended...\" % (file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe is :  (3976222, 21)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the appended dataframe\n",
    "print(\"Shape of the dataframe is : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>no</th>\n",
       "      <th>id_auditor</th>\n",
       "      <th>id_outlet</th>\n",
       "      <th>OutletSize</th>\n",
       "      <th>OutletBranding</th>\n",
       "      <th>OutletLocation</th>\n",
       "      <th>CITY</th>\n",
       "      <th>SUBREGION</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Typeofpack</th>\n",
       "      <th>Type</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NominalofData/SMS</th>\n",
       "      <th>TypeofData/SMS</th>\n",
       "      <th>NominalofPulsa</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sellingprice</th>\n",
       "      <th>TotalSellingPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ma10011</td>\n",
       "      <td>111406</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7/4/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ma10011</td>\n",
       "      <td>111406</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7/4/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ma10011</td>\n",
       "      <td>111406</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7/4/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ma10011</td>\n",
       "      <td>111406</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7/4/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>ma10011</td>\n",
       "      <td>111406</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7/4/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIAL  no id_auditor  id_outlet  OutletSize  OutletBranding  \\\n",
       "0       1   1    ma10011     111406           4               1   \n",
       "1       2   2    ma10011     111406           4               1   \n",
       "2       3   3    ma10011     111406           4               1   \n",
       "3       4   4    ma10011     111406           4               1   \n",
       "4       5   5    ma10011     111406           4               1   \n",
       "\n",
       "   OutletLocation  CITY  SUBREGION      Date        ...          Typeofpack  \\\n",
       "0               2    35          7  7/4/2017        ...                   5   \n",
       "1               2    35          7  7/4/2017        ...                   5   \n",
       "2               2    35          7  7/4/2017        ...                   5   \n",
       "3               2    35          7  7/4/2017        ...                   5   \n",
       "4               2    35          7  7/4/2017        ...                   5   \n",
       "\n",
       "   Type  Operator  Brand  NominalofData/SMS  TypeofData/SMS NominalofPulsa  \\\n",
       "0     3         1      1                1.0              GB            NaN   \n",
       "1     3         3      5                6.0              GB            NaN   \n",
       "2     3         3      5               12.0              GB            NaN   \n",
       "3     3         1      2                5.0              GB            NaN   \n",
       "4     3         2      3               10.0              GB            NaN   \n",
       "\n",
       "   Quantity  Sellingprice  TotalSellingPrice  \n",
       "0         1          16.0               16.0  \n",
       "1         1          65.0               65.0  \n",
       "2         1          60.0               60.0  \n",
       "3         1          40.0               40.0  \n",
       "4         1          50.0               50.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the head of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERIAL               0.000000\n",
       "no                   0.000000\n",
       "id_auditor           0.000000\n",
       "id_outlet            0.000000\n",
       "OutletSize           0.000000\n",
       "OutletBranding       0.000000\n",
       "OutletLocation       0.000000\n",
       "CITY                 0.000000\n",
       "SUBREGION            0.000000\n",
       "Date                 0.000000\n",
       "Period               0.000000\n",
       "Typeofpack           0.000000\n",
       "Type                 0.000000\n",
       "Operator             0.000000\n",
       "Brand                0.000000\n",
       "NominalofData/SMS    0.910488\n",
       "TypeofData/SMS       0.921614\n",
       "NominalofPulsa       0.078871\n",
       "Quantity             0.000000\n",
       "Sellingprice         0.000000\n",
       "TotalSellingPrice    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the percentage of missing values \n",
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NominalofFata/SMS** and **TypeofData/SMS** have unusually high rate of missing values. Hence it is better to drop them. For **NominalofPulsa** it is better to impute it with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe before dropping is :  (3976222, 21)\n",
      "Shape of the dataframe before dropping is :  (3976222, 19)\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop\n",
    "drop_cols = ['NominalofData/SMS', 'TypeofData/SMS']\n",
    "\n",
    "# Drop the columns\n",
    "print(\"Shape of the dataframe before dropping is : \", df.shape)\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "print(\"Shape of the dataframe before dropping is : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with the median\n",
    "df['NominalofPulsa'] = df['NominalofPulsa'].fillna(df['NominalofPulsa'].median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERIAL               0.0\n",
       "no                   0.0\n",
       "id_auditor           0.0\n",
       "id_outlet            0.0\n",
       "OutletSize           0.0\n",
       "OutletBranding       0.0\n",
       "OutletLocation       0.0\n",
       "CITY                 0.0\n",
       "SUBREGION            0.0\n",
       "Date                 0.0\n",
       "Period               0.0\n",
       "Typeofpack           0.0\n",
       "Type                 0.0\n",
       "Operator             0.0\n",
       "Brand                0.0\n",
       "NominalofPulsa       0.0\n",
       "Quantity             0.0\n",
       "Sellingprice         0.0\n",
       "TotalSellingPrice    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check if the operations have been performed properly\n",
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map values according to data dictionary\n",
    "\n",
    "We have created an excel file called **mapping.xlsx** based on **code.xlsx**. The aim is to read this file as a dictionary and repace values based on it, rather than code for it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the name of the mapping file\n",
    "file = \"mapping.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mapping for city\n",
    "cityMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='city', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for subregion\n",
    "subregionMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='subregion', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for outlet size\n",
    "outletsizeMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='outletsize', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for outlet branding\n",
    "outletbrandingMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='outletbranding', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for outlet location\n",
    "outletlocationMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='outletlocation', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for type of pack\n",
    "typeofpackMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='typeofpack', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for type\n",
    "typeMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='type', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for operator\n",
    "operatorMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='operator', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for brand\n",
    "brandMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='brand', header=None, squeeze=True, index_col=0).to_dict()\n",
    "\n",
    "# Read the mapping for id outlet\n",
    "idoutletMapping = pd.read_excel(os.path.join(DATA_INPUT, file), sheet_name='idoutlet', header=None, squeeze=True, index_col=0).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our mapping files, its time to change these at our main dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for city\n",
    "df['CITY'] = df['CITY'].map(cityMapping)\n",
    "\n",
    "# Map for subregion\n",
    "df['SUBREGION'] = df['SUBREGION'].map(subregionMapping)\n",
    "\n",
    "# Map for outlet size\n",
    "df['OutletSize'] = df['OutletSize'].map(outletsizeMapping)  \n",
    "\n",
    "# Map for outlet branding\n",
    "df['OutletBranding'] = df['OutletBranding'].map(outletbrandingMapping)  \n",
    "\n",
    "# Map for outlet location\n",
    "df['OutletLocation'] = df['OutletLocation'].map(outletlocationMapping)  \n",
    "\n",
    "# Map for type of pack\n",
    "df['Typeofpack'] = df['Typeofpack'].map(typeofpackMapping)  \n",
    "\n",
    "# Map for type\n",
    "df['Type'] = df['Type'].map(typeMapping)  \n",
    "\n",
    "# Map for operator\n",
    "df['Operator'] = df['Operator'].map(operatorMapping)  \n",
    "\n",
    "# Map for brand\n",
    "df['Brand'] = df['Brand'].map(brandMapping)  \n",
    "\n",
    "# Map for id outlet\n",
    "df['id_outlet'] = df['id_outlet'].map(idoutletMapping)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify date column appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the data types of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERIAL                 int64\n",
       "no                     int64\n",
       "id_auditor            object\n",
       "id_outlet             object\n",
       "OutletSize            object\n",
       "OutletBranding        object\n",
       "OutletLocation        object\n",
       "CITY                  object\n",
       "SUBREGION             object\n",
       "Date                  object\n",
       "Period                 int64\n",
       "Typeofpack            object\n",
       "Type                  object\n",
       "Operator              object\n",
       "Brand                 object\n",
       "NominalofPulsa       float64\n",
       "Quantity               int64\n",
       "Sellingprice         float64\n",
       "TotalSellingPrice    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date column has been represented as a string here. We need to change it to date format. Here is how we would do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us extract the month name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making lag variables\n",
    "\n",
    "To forecast for the next month, it is imperative that we add a lag variable by shifting TotalSellingPrice by 30. For 3 months forecasting, all we need to do is change this value to 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a lag variable\n",
    "df['Lag1'] = df['TotalSellingPrice'].shift(30)\n",
    "df['Lag1'] = df['Lag1'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns which are not required\n",
    "\n",
    "There are few columns which are not going to be needed later on. Having a look at brand and operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Operator</th>\n",
       "      <th>3 (THREE)</th>\n",
       "      <th>Bolt</th>\n",
       "      <th>Indosat Ooredoo</th>\n",
       "      <th>SMARTFREN</th>\n",
       "      <th>Telkomsel</th>\n",
       "      <th>XL Axiata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3 (THREE)</th>\n",
       "      <td>383685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXIS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolt</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>625619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KARTU AS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>781261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOOP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MENTARI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIMPATI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>970824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMARTFREN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XL PRABAYAR</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>534579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Operator     3 (THREE)  Bolt  Indosat Ooredoo  SMARTFREN  Telkomsel  XL Axiata\n",
       "Brand                                                                         \n",
       "3 (THREE)       383685     0                0          0          0          0\n",
       "AXIS                 0     0                0          0          0     244348\n",
       "Bolt                 0    97                0          0          0          0\n",
       "IM3                  0     0           625619          0          0          0\n",
       "KARTU AS             0     0                0          0     781261          0\n",
       "LOOP                 0     0                0          0     156649          0\n",
       "MENTARI              0     0           228255          0          0          0\n",
       "SIMPATI              0     0                0          0     970824          0\n",
       "SMARTFREN            0     0                0      50905          0          0\n",
       "XL PRABAYAR          0     0                0          0          0     534579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check relationship between brand and operator\n",
    "df.pivot_table(index=\"Brand\", columns=\"Operator\", aggfunc='count', fill_value=0, values=\"id_outlet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, it is clear that each brand is only exclusive to a particular operator. Hence it is better to keep only one of these columns. We shall be keeping brand and dropping operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Type</th>\n",
       "      <th>Data Inject</th>\n",
       "      <th>Reload</th>\n",
       "      <th>Starter Pack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typeofpack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kartu Perdana - data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kartu Perdana - regular</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher Elektronik - Paket Internet</th>\n",
       "      <td>54292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher Elektronik - Paket SMS</th>\n",
       "      <td>0</td>\n",
       "      <td>5536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher Elektronik - Pulsa</th>\n",
       "      <td>0</td>\n",
       "      <td>3520039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher Fisik - Paket Internet</th>\n",
       "      <td>39936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher Fisik - Pulsa</th>\n",
       "      <td>0</td>\n",
       "      <td>48374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Type                                 Data Inject   Reload  Starter Pack\n",
       "Typeofpack                                                             \n",
       "Kartu Perdana - data                           0        0        211917\n",
       "Kartu Perdana - regular                        0        0         96128\n",
       "Voucher Elektronik - Paket Internet        54292        0             0\n",
       "Voucher Elektronik - Paket SMS                 0     5536             0\n",
       "Voucher Elektronik - Pulsa                     0  3520039             0\n",
       "Voucher Fisik - Paket Internet             39936        0             0\n",
       "Voucher Fisik - Pulsa                          0    48374             0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check relationship between typeofpack and type\n",
    "df.pivot_table(index=\"Typeofpack\", columns=\"Type\", aggfunc='count', fill_value=0, values=\"id_outlet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, it is clear that each typeofpack is only exclusive to a particular type. Hence it is better to keep only one of these columns. We shall be keeping typeofpack. Likewise, id_auditor and id_outlet have been found to have a similar relationship when checked via an Excel pivot. The only different part would be:\n",
    "\n",
    "+ We will be aggregating data at id_outlet level.\n",
    "+ We want to know the effect of the model at each outlet level.\n",
    "+ We cannot let the algorithm get affected by the cardinality of the number of outlets. The ideal solution would be to group these and then feed them as dummy variables into the model. Hence since, id_auditor has an exclusive relationship with id_outlet, we may consider this as grouping in itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe before dropping is :  (3976222, 21)\n",
      "Shape of the dataframe before dropping is :  (3976222, 14)\n"
     ]
    }
   ],
   "source": [
    "# Specify columns to drop. SERIAL and no have no implication on modelling, neither are they unique identifiers. \n",
    "drop_cols = ['SERIAL', 'no', 'Sellingprice', 'Quantity', 'Date', 'Operator', 'Type']\n",
    "\n",
    "# Drop the columns\n",
    "print(\"Shape of the dataframe before dropping is : \", df.shape)\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "print(\"Shape of the dataframe before dropping is : \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the key to aggregate data at\n",
    "\n",
    "We shall be aggregating data at id_outlet and Month level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the key on id_outlet and Month\n",
    "df['key'] = df['id_outlet'] + df['Month']\n",
    "drop_cols = ['Month', 'id_outlet']\n",
    "\n",
    "# Drop the unrequired columns\n",
    "df = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummify categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns which need not be dummified\n",
    "req_cols = ['NominalofPulsa', 'key', 'TotalSellingPrice', 'Lag1']\n",
    "\n",
    "# Columns which need dummification are the total columns - the columns mentioned above\n",
    "dummify_cols = df.copy().drop(req_cols, axis=1).columns.tolist()\n",
    "\n",
    "# Dummify the data \n",
    "master = pd.get_dummies(df, columns=dummify_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the master data is : (6798, 175)\n"
     ]
    }
   ],
   "source": [
    "# Roll up the data on the key specified\n",
    "master = master.groupby('key').sum()\n",
    "\n",
    "# Print shape of the master data\n",
    "print(\"Shape of the master data is :\", master.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capping the target variable\n",
    "\n",
    "Let us have a look at the target variable distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      6798.000000\n",
       "mean      10146.225552\n",
       "std        9971.681513\n",
       "min           8.000000\n",
       "10%         704.700000\n",
       "20%        1348.000000\n",
       "25%        2537.500000\n",
       "30%        4086.300000\n",
       "40%        6639.400000\n",
       "50%        8444.500000\n",
       "60%       10102.600000\n",
       "70%       12225.700000\n",
       "75%       13494.750000\n",
       "80%       14986.800000\n",
       "90%       22018.100000\n",
       "99%       44715.840000\n",
       "max      221801.000000\n",
       "Name: TotalSellingPrice, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = [0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9, 0.99]\n",
    "master['TotalSellingPrice'].describe(percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall be capping the value at the 99th percentile so as to not skew our model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPPED_VALUE = master['TotalSellingPrice'].describe(percentiles)[15]\n",
    "master['TotalSellingPrice'] = np.where(master['TotalSellingPrice'] > CAPPED_VALUE, CAPPED_VALUE, master['TotalSellingPrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the dummy variables appropriately\n",
    "\n",
    "We shall be changing the dummy variables which are greater than 1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick all the columns except the numerical column and the target\n",
    "req_cols = ['NominalofPulsa', 'TotalSellingPrice', 'Lag1']\n",
    "change_cols = master.copy().drop(req_cols, axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "# Change dummy cols appropriately\n",
    "master[change_cols] = master[change_cols].applymap(lambda x: 1 if 1 <= x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output master data into pickle for modelling purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results to pickle file\n",
    "master.to_pickle(os.path.join(DATA_OUTPUT, \"master.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
